{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"Contains the functions preprocessing the data, or grabing the data\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fftpack  # Fourier\n",
    "from scipy.ndimage import maximum_filter1d\n",
    "from librosa.feature import mfcc, spectral_contrast, zero_crossing_rate\n",
    "from tqdm import tqdm\n",
    "from tsfresh.feature_extraction import feature_calculators as fc\n",
    "import pywt\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "PATH_DATA = \"../data/\"\n",
    "COLORS = [\"#263554\", \"#D85604\", \"#E88D14\"]\n",
    "\n",
    "\n",
    "def plot(data, col):\n",
    "    fig = figure(title=f\"Evolution de {col}\", x_range=(0, len(data)),\n",
    "                 plot_width=800, plot_height=300)\n",
    "    fig.xaxis.axis_label = 'Time (s)'\n",
    "    fig.grid.visible = False\n",
    "    fig.line(x=\"index\", y=col, source=data)\n",
    "    show(fig)\n",
    "\n",
    "\n",
    "def load_segment(segment_id):\n",
    "    \"\"\"Returns the data about a specific segment_id\"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(f\"{PATH_DATA}train/{segment_id}.csv\")\n",
    "    except FileNotFoundError:\n",
    "        return pd.read_csv(f\"{PATH_DATA}test/{segment_id}.csv\")\n",
    "\n",
    "\n",
    "def get_index(target=\"train\"):\n",
    "    \"\"\"Returns the list of segments of a set (train or test)\"\"\"\n",
    "    file = \"train\" if target == \"train\" else \"sample_submission\"\n",
    "    data = pd.read_csv(f\"{PATH_DATA}{file}.csv\")\n",
    "    return data[\"segment_id\"].values\n",
    "\n",
    "\n",
    "def maddest(serie, axis=None):\n",
    "    \"\"\"Returns the mean of de deviation of a serie\"\"\"\n",
    "    return np.mean(np.absolute(serie - np.mean(serie, axis)), axis)\n",
    "\n",
    "\n",
    "def denoise_signal_simple(x, wavelet='db4', level=1):\n",
    "    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "    coeff[1:] = (pywt.threshold(i, value=10,\n",
    "                                mode='hard') for i in coeff[1:])\n",
    "    return pywt.waverec(coeff, wavelet, mode='per')\n",
    "\n",
    "\n",
    "def get_features(sig, sensor_id):\n",
    "    \"\"\"Analysis of a signal. Grabs temporal and frequential features.\n",
    "    Returns a pandas dataframe\"\"\"\n",
    "\n",
    "    fourier = fftpack.fft(sig.values)\n",
    "    real, imag = np.real(fourier), np.imag(fourier)\n",
    "\n",
    "    # Temporal data\n",
    "    features = {}\n",
    "    features[f\"{sensor_id}_mean\"] = [sig.mean()]\n",
    "    features[f\"{sensor_id}_var\"] = [sig.var()]\n",
    "    features[f\"{sensor_id}_skew\"] = [sig.skew()]\n",
    "    features[f\"{sensor_id}_delta\"] = [sig.max() - sig.min()]\n",
    "    features[f\"{sensor_id}_mad\"] = [sig.mad()]\n",
    "    features[f\"{sensor_id}_kurtosis\"] = [sig.kurtosis()]\n",
    "    features[f\"{sensor_id}_sem\"] = [sig.sem()]\n",
    "    features[f\"{sensor_id}_q5\"] = [np.quantile(sig, 0.05)]\n",
    "    features[f\"{sensor_id}_q25\"] = [np.quantile(sig, 0.25)]\n",
    "    features[f\"{sensor_id}_q75\"] = [np.quantile(sig, 0.75)]\n",
    "    features[f\"{sensor_id}_q95\"] = [np.quantile(sig, 0.95)]\n",
    "    grad_rol_max = [maximum_filter1d(np.gradient(np.abs(sig.values)), 50)]\n",
    "    delta = np.max(grad_rol_max) - np.min(grad_rol_max)\n",
    "    features[f\"{sensor_id}_grmax_delta\"] = delta\n",
    "\n",
    "    # Frequencial\n",
    "    features[f\"{sensor_id}_real_mean\"] = [real.mean()]\n",
    "    features[f\"{sensor_id}_real_var\"] = [real.var()]\n",
    "    features[f\"{sensor_id}_real_delta\"] = [real.max() - real.min()]\n",
    "\n",
    "    features[f\"{sensor_id}_imag_mean\"] = [imag.mean()]\n",
    "    features[f\"{sensor_id}_imag_var\"] = [imag.var()]\n",
    "    features[f\"{sensor_id}_imag_delta\"] = [imag.max() - imag.min()]\n",
    "\n",
    "    features[f\"{sensor_id}_nb_peak\"] = fc.number_peaks(sig.values, 2)\n",
    "    features[f\"{sensor_id}_median_roll_std\"] = np.median(\n",
    "        pd.Series(sig).rolling(50).std().dropna().values)\n",
    "    features[f\"{sensor_id}_autocorr5\"] = fc.autocorrelation(sig, 5)\n",
    "\n",
    "    # Added 16\n",
    "    features[f\"{sensor_id}_nb_peak_3\"] = fc.number_peaks(sig.values, 3)\n",
    "    features[f\"{sensor_id}_absquant95\"] = np.quantile(np.abs(sig), 0.95)\n",
    "\n",
    "    try:\n",
    "        # Mel-frequency cepstral coefficients\n",
    "        mfcc_mean = mfcc(sig.values).mean(axis=1)\n",
    "        for i in range(20):\n",
    "            features[f\"{sensor_id}_mfcc_mean_{i}\"] = mfcc_mean[i]\n",
    "        # Contrast spectral\n",
    "        spec_contrast = spectral_contrast(sig.values).mean(axis=1)\n",
    "        for i in range(7):\n",
    "            features[f\"{sensor_id}_lib_spec_cont_{i}\"] = spec_contrast[i]\n",
    "        features[f\"{sensor_id}_zero_cross\"] = zero_crossing_rate(sig)[0].mean()\n",
    "        # Added 16\n",
    "        features[f\"{sensor_id}_percentile_roll20_std_50\"] = np.percentile(\n",
    "            sig.rolling(20).std().dropna().values, 50)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# =============================================================================\n",
    "    # fftrhann20000 = np.sum(np.abs(np.fft.fft(np.hanning(len(z))*z)[:20000]))\n",
    "    # fftrhann20000_denoise = np.sum(np.abs(np.fft.fft(np.hanning(len(z))*den_sample)[:20000]))\n",
    "    # fftrhann20000_diff_rate = (fftrhann20000 - fftrhann20000_denoise)/fftrhann20000\n",
    "    # X['LGBM_fftrhann20000_diff_rate'] = fftrhann20000_diff_rate\n",
    "# =============================================================================\n",
    "    return pd.DataFrame.from_dict(features)\n",
    "\n",
    "\n",
    "def preprocess_data(target=\"train\"):\n",
    "    \"\"\"Generates a dataframe containing all the features of a\n",
    "    dataset (train or test)\"\"\"\n",
    "    data_set = []\n",
    "    for seg in tqdm(get_index(target)):\n",
    "        train_row = [pd.DataFrame.from_dict({\"segment_id\": [seg]})]\n",
    "        data = load_segment(seg)\n",
    "        for i in range(10):\n",
    "            sensor_id = f\"sensor_{i+1}\"\n",
    "            train_row.append(get_features(data[sensor_id], sensor_id))\n",
    "        train_row = pd.concat(train_row, axis=1)\n",
    "        data_set.append(train_row)\n",
    "\n",
    "    data_set = pd.concat(data_set).reset_index()\n",
    "    data_set.fillna(-1, inplace=True)\n",
    "    data_set.drop(['index'], axis=1, inplace=True)\n",
    "    return data_set\n",
    "\n",
    "\n",
    "def lr_decay(current_iter):\n",
    "    return max(1e-1, 0.29 * np.power(.9985, current_iter))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infrapy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
