{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beamforming\n",
    "\n",
    "Run Bartlett, Capon or Generalized Least Squares beamforming processes on an hour-long dataset from the BRP array in Utah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocess import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "palette = cm.jet\n",
    "import matplotlib.ticker as mtick\n",
    "from obspy.core import read\n",
    "from scipy import signal\n",
    "from infrapy.detection import beamforming_new\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################### #\n",
    "#     Define Parameters     #\n",
    "# ######################### #\n",
    "sac_glob = \"data\\IM.I04H1..BDF.MSEED\" ## load in SAC files for processing\n",
    "\n",
    "freq_min, freq_max = 0.5, 2.5 ## define frequency band of interest\n",
    "window_length, window_step = 10.0, 2.5 ## define window length and window step for beamforming\n",
    "\n",
    "ns_start, ns_end = 100.0, 400.0 ## define noise window (in sec); only needed for GLS processing\n",
    "sig_start, sig_end = 600, 800 ## define signal window [time window in sec used for analysis]\n",
    "\n",
    "back_az_vals = np.arange(-180.0, 180.0, 1.5)\n",
    "trc_vel_vals = np.arange(300.0, 600.0, 2.5)\n",
    "\n",
    "method=\"bartlett\" ## beamforming method; options are bartlett, capon, GLS\n",
    "\n",
    "p = Pool(4) ## define number of CPUs used for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "sac",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\mhayk\\anaconda3\\envs\\infrapy_env\\lib\\site-packages\\obspy\\core\\util\\attribdict.py:128\u001b[0m, in \u001b[0;36mAttribDict.__getattr__\u001b[1;34m(self, name, default)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(name, default)\n\u001b[0;32m    129\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\mhayk\\anaconda3\\envs\\infrapy_env\\lib\\site-packages\\obspy\\core\\trace.py:235\u001b[0m, in \u001b[0;36mStats.__getitem__\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 235\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Stats, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(key, default)\n",
      "File \u001b[1;32mc:\\Users\\mhayk\\anaconda3\\envs\\infrapy_env\\lib\\site-packages\\obspy\\core\\util\\attribdict.py:74\u001b[0m, in \u001b[0;36mAttribDict.__getitem__\u001b[1;34m(self, name, default)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__dict__\u001b[39;49m[name]\n\u001b[0;32m     75\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     \u001b[39m# check if we got any default value given at class level\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sac'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# ######################### #\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#  Read, Shift Start Time,  #\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#      and Filter Data      #\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# ######################### #\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m x, t, t0, geom \u001b[39m=\u001b[39m beamforming_new\u001b[39m.\u001b[39;49mstream_to_array_data(read(sac_glob))\n\u001b[0;32m      6\u001b[0m M, N \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\users\\mhayk\\infrapy\\infrapy\\detection\\beamforming_new.py:85\u001b[0m, in \u001b[0;36mstream_to_array_data\u001b[1;34m(stream, latlon, t_start, t_end)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mif\u001b[39;00m latlon \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m     \u001b[39mfor\u001b[39;00m m, tr \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(stream):\n\u001b[1;32m---> 85\u001b[0m         temp \u001b[39m=\u001b[39m wgs84_proj\u001b[39m.\u001b[39minv(stream[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mstats\u001b[39m.\u001b[39;49msac[\u001b[39m'\u001b[39m\u001b[39mstlo\u001b[39m\u001b[39m'\u001b[39m], stream[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstats\u001b[39m.\u001b[39msac[\u001b[39m'\u001b[39m\u001b[39mstla\u001b[39m\u001b[39m'\u001b[39m], tr\u001b[39m.\u001b[39mstats\u001b[39m.\u001b[39msac[\u001b[39m'\u001b[39m\u001b[39mstlo\u001b[39m\u001b[39m'\u001b[39m], tr\u001b[39m.\u001b[39mstats\u001b[39m.\u001b[39msac[\u001b[39m'\u001b[39m\u001b[39mstla\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     86\u001b[0m         dxdy[m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray((temp[\u001b[39m2\u001b[39m] \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msin(np\u001b[39m.\u001b[39mradians(temp[\u001b[39m0\u001b[39m])), temp[\u001b[39m2\u001b[39m] \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mcos(np\u001b[39m.\u001b[39mradians(temp[\u001b[39m0\u001b[39m]))))\n\u001b[0;32m     87\u001b[0m     \u001b[39m# Or using 'Coordinate' from stats\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[39m# ...\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mhayk\\anaconda3\\envs\\infrapy_env\\lib\\site-packages\\obspy\\core\\util\\attribdict.py:130\u001b[0m, in \u001b[0;36mAttribDict.__getattr__\u001b[1;34m(self, name, default)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(name, default)\n\u001b[0;32m    129\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(e\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: sac"
     ]
    }
   ],
   "source": [
    "# ######################### #\n",
    "#  Read, Shift Start Time,  #\n",
    "#      and Filter Data      #\n",
    "# ######################### #\n",
    "x, t, t0, geom = beamforming_new.stream_to_array_data(read(sac_glob))\n",
    "M, N = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute('style', 'box-sizing: content-box;');\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            canvas.setAttribute(\n                'style',\n                'width: ' + width + 'px; height: ' + height + 'px;'\n            );\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        return function (event) {\n            return fig.mouse_event(event, name);\n        };\n    }\n\n    rubberband_canvas.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    rubberband_canvas.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    rubberband_canvas.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    rubberband_canvas.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    rubberband_canvas.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    rubberband_canvas.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.rubberband_canvas.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\n// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\nmpl.findpos = function (e) {\n    //this section is from http://www.quirksmode.org/js/events_properties.html\n    var targ;\n    if (!e) {\n        e = window.event;\n    }\n    if (e.target) {\n        targ = e.target;\n    } else if (e.srcElement) {\n        targ = e.srcElement;\n    }\n    if (targ.nodeType === 3) {\n        // defeat Safari bug\n        targ = targ.parentNode;\n    }\n\n    // pageX,Y are the mouse positions relative to the document\n    var boundingRect = targ.getBoundingClientRect();\n    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n\n    return { x: x, y: y };\n};\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    var canvas_pos = mpl.findpos(event);\n\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    var x = canvas_pos.x * this.ratio;\n    var y = canvas_pos.y * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        guiEvent: simpleKeys(event),\n    });\n\n    /* This prevents the web browser from automatically changing to\n     * the text insertion cursor when the button is pressed.  We want\n     * to control all of the cursor setting manually through the\n     * 'cursor' event from matplotlib */\n    event.preventDefault();\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='0c674110-d213-4624-8dff-c499a7de2b47'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'M' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# ######################### #\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#         View Data         #\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# ######################### #\u001b[39;00m\n\u001b[0;32m      4\u001b[0m plt\u001b[39m.\u001b[39mfigure()\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(M):\n\u001b[0;32m      6\u001b[0m     plt\u001b[39m.\u001b[39msubplot(M, \u001b[39m1\u001b[39m, m \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m     plt\u001b[39m.\u001b[39mxlim([\u001b[39m0\u001b[39m, t[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'M' is not defined"
     ]
    }
   ],
   "source": [
    "# ######################### #\n",
    "#         View Data         #\n",
    "# ######################### #\n",
    "plt.figure()\n",
    "for m in range(M):\n",
    "    plt.subplot(M, 1, m + 1)\n",
    "    plt.xlim([0, t[-1]])\n",
    "    plt.plot(t, x[m], 'k-')\n",
    "    plt.axvspan(xmin = sig_start , xmax = sig_end, alpha = 0.25, color = 'blue')\n",
    "    if method == \"gls\":\n",
    "        plt.axvspan(xmin = ns_start , xmax = ns_end, alpha = 0.25, color = 'red')\n",
    "    if m < (M - 1) : plt.setp(plt.subplot(M, 1, m + 1).get_xticklabels(), visible=False)\n",
    "\n",
    "if method == \"gls\":\n",
    "    plt.suptitle(\"Data windows for signal (blue) and noise (red) \\n Filtered in frequency range: \" + str(freq_min) + \" - \" + str(freq_max) + \"  Hz \\n \")\n",
    "else:\n",
    "    plt.suptitle(\"Data window for analysis \\n Filtered in frequency range: \" + str(freq_min) + \" - \" + str(freq_max) + \"  Hz \\n \")\n",
    "\n",
    "plt.show(block=False)\n",
    "plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################### #\n",
    "#        Run Methods        #\n",
    "# ######################### #\n",
    "\n",
    "# define slowness and delays\n",
    "slowness = beamforming_new.build_slowness(back_az_vals, trc_vel_vals)\n",
    "delays = beamforming_new.compute_delays(geom, slowness)\n",
    "\n",
    "# define the noise covariance if using generalized least squares method\n",
    "if method == \"gls\":\n",
    "    _, S, _ = beamforming_new.fft_array_data(x, t, window=[ns_start, ns_end], sub_window_len=window_length)\n",
    "\n",
    "    ns_covar_inv = np.empty_like(S)\n",
    "    for n in range(S.shape[2]):\n",
    "        S[:, :, n] += 1.0e-3 * np.mean(np.diag(S[:, :, n])) * np.eye(S.shape[0])\n",
    "        ns_covar_inv[:, :, n] = np.linalg.inv(S[:, :, n])\n",
    "else:\n",
    "    ns_covar_inv = None\n",
    "\n",
    "\n",
    "\n",
    "# Run beamforming in windowed data and write to file\n",
    "times, beam_results = [],[]\n",
    "for window_start in np.arange(sig_start, sig_end, window_step):\n",
    "    if window_start + window_length > sig_end:\n",
    "        break\n",
    "\n",
    "    times = times + [[t0 + np.timedelta64(int(window_start), 's')]]\n",
    "    X, S, f = beamforming_new.fft_array_data(x, t, window=[window_start, window_start + window_length])\n",
    "    beam_power = beamforming_new.run(X, S, f, geom, delays, [freq_min, freq_max], method=\"bartlett\", pool=p, normalize_beam=True, ns_covar_inv=ns_covar_inv)\n",
    "    peaks = beamforming_new.find_peaks(beam_power, back_az_vals, trc_vel_vals, signal_cnt=1)\n",
    "    beam_results = beam_results + [[peaks[0][0], peaks[0][1], peaks[0][2] / (1.0 - peaks[0][2]) * (x.shape[0] - 1)]]\n",
    "\n",
    "times = np.array(times)[:, 0]\n",
    "beam_results = np.array(beam_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep figure\n",
    "f, a = plt.subplots(4, sharex=True)\n",
    "plt.xlim([sig_start, sig_end])\n",
    "a[3].set_xlabel(\"Time [s]\")\n",
    "a[3].set_ylabel(\"Pr. [Pa]\")\n",
    "a[2].set_ylabel(\"Back Az. [deg.]\")\n",
    "a[1].set_ylabel(\"Tr. Vel. [m/s]\")\n",
    "if method == \"music\":\n",
    "    a[0].set_ylabel(\"Beam Power\")\n",
    "else:\n",
    "    a[0].set_ylabel(\"log10(F-value)\")\n",
    "\n",
    "a[3].plot(t, x[1,:], '-k')\n",
    "plt.suptitle(\"Frequency range: \" + str(freq_min) + \" - \" + str(freq_max) + \" Hz \\n window size \" + str(window_length) + \" seconds, window step \" + str(window_step) +  \" seconds\")\n",
    "\n",
    "for aa in range(len(times)):\n",
    "    dt = times[aa]-times[0]\n",
    "    start = dt.item().total_seconds() \n",
    "    start = start + sig_start\n",
    "    if method == \"music\":\n",
    "        a[2].plot([start + 1.0 / 2.0 * window_length], [beam_results[aa][0]], 'ok', markersize=3.3)\n",
    "        a[1].plot([start + 1.0 / 2.0 * window_length], [beam_results[aa][1]], 'ok', markersize=3.3)\n",
    "        a[0].plot([start + 1.0 / 2.0 * window_length], [beam_results[aa][2]], 'ok', markersize=3.3)\n",
    "        plt.pause(0.1)\n",
    "    else:\n",
    "        a[2].plot([start + 1.0 / 2.0 * window_length], [beam_results[aa][0]], 'ok', markersize=3.3)\n",
    "        a[1].plot([start + 1.0 / 2.0 * window_length], [beam_results[aa][1]], 'ok', markersize=3.3)\n",
    "        a[0].plot([start + 1.0 / 2.0 * window_length], [beam_results[aa][2]], 'ok', markersize=3.3)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################## #\n",
    "#        Save Results        #\n",
    "# ########################## #\n",
    "\n",
    "np.save(\"times\", times)\n",
    "np.save(\"beam_results\", beam_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################### #\n",
    "#        Define Beam and Residuals        #\n",
    "# ####################################### #\n",
    "back_az = beam_results[np.argmax(beam_results[:, 2]), 0]\n",
    "tr_vel = beam_results[np.argmax(beam_results[:, 2]), 1]\n",
    "\n",
    "X, S, f = beamforming_new.fft_array_data(x, t, window=[sig_start, sig_end], fft_window=\"boxcar\")\n",
    "sig_est, residual = beamforming_new.extract_signal(X, f, np.array([back_az, tr_vel]), geom)\n",
    "\n",
    "plt.figure()\n",
    "plt.loglog(f, abs(sig_est), '-b', linewidth=1.0)\n",
    "plt.loglog(f, np.mean(abs(residual), axis=0), '-k', linewidth=0.5)\n",
    "\n",
    "signal_wvfrm = np.fft.irfft(sig_est) / (t[1] - t[0])\n",
    "resid_wvfrms = np.fft.irfft(residual, axis=1) / (t[1] - t[0])\n",
    "t_mask = np.logical_and(sig_start < t, t < sig_end)\n",
    "\n",
    "plt.figure()\n",
    "for m in range(M):\n",
    "    plt.subplot(M + 1, 1, m + 1)\n",
    "    plt.xlim([t[t_mask][0], t[t_mask][-1]])\n",
    "    plt.plot(t[t_mask], x[m, t_mask], '0.5')\n",
    "    plt.plot(t[t_mask], resid_wvfrms[m, :len(t[t_mask])], 'k-')\n",
    "    plt.setp(plt.subplot(M + 1, 1, m + 1).get_xticklabels(), visible=False)\n",
    "plt.subplot(M + 1, 1, M + 1)\n",
    "plt.xlim([t[t_mask][0], t[t_mask][-1]])\n",
    "plt.plot(t[t_mask], signal_wvfrm[:len(t[t_mask])], 'b-')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection\n",
    "\n",
    "Run detection on the series of beamforming results produced in the above step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################### #\n",
    "#     Define Parameters     #\n",
    "# ######################### #\n",
    "\n",
    "# Detection params\n",
    "# times_file, beam_results_file = None, None\n",
    "times_file, beam_results_file = \"times.npy\", \"beam_results.npy\"\n",
    "\n",
    "det_win_len = 60 * 5\n",
    "det_thresh = 0.99\n",
    "min_seq = 5\n",
    "det_method = \"fstat\"\n",
    "TB_prod = 40 * 10\n",
    "back_az_lim = 10\n",
    "M=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################## #\n",
    "#   Load data and prepare analysis   #\n",
    "# ################################## #\n",
    "\n",
    "if times_file and beam_results_file:\n",
    "    times = np.load(times_file)\n",
    "    beam_results = np.load(beam_results_file)\n",
    "else:\n",
    "    print('No beamforming input provided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################## #\n",
    "#       Run detection analysis       #\n",
    "# ################################## #\n",
    "\n",
    "dets = beamforming_new.detect_signals(times, beam_results, det_win_len, TB_prod, channel_cnt=M, det_thresh=det_thresh, min_seq=min_seq, back_az_lim=back_az_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################## #\n",
    "#       Print Detection Summary      #\n",
    "# ################################## #\n",
    "print('\\n' + \"Detection Summary:\")\n",
    "for det in dets:\n",
    "    print(\"Detection time:\", det[0], '\\t', \"Rel. detection onset:\", det[1], '\\t',\"Rel. detection end:\", det[2], '\\t',end=' ')\n",
    "    print(\"Back azimuth:\", det[3], '\\t', \"Trace velocity:\", det[4], '\\t', \"F-stat:\", det[5], '\\t', \"Array dim:\", M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(a, a0):\n",
    "    \"Element in nd array `a` closest to the scalar value `a0`\"\n",
    "    idx = np.abs(a - a0).argmin()\n",
    "    return a.flat[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################## #\n",
    "#       Plot Detection Results       #\n",
    "# ################################## #\n",
    "\n",
    "plt.figure()\n",
    "plt.suptitle(\"Detection results for analysis \\n Filtered in frequency range: \" + str(freq_min) + \" - \" + str(freq_max) + \"  Hz \\n \")\n",
    "\n",
    "for det in range(len(dets)):\n",
    "    dt = dets[det][0]-times[0] \n",
    "    start = dt.item().total_seconds() \n",
    "    ts = sig_start + start + dets[det][1]\n",
    "    te = sig_start + start + dets[det][2]\n",
    "    for m in range(M):\n",
    "        plt.subplot(M, 1, m + 1)\n",
    "        plt.xlim([sig_start, sig_end])\n",
    "        plt.plot(t, x[m], 'k-')\n",
    "        plt.axvspan(xmin = ts , xmax = te, alpha = 0.25, color = 'red')\n",
    "        if m < (M - 1) : plt.setp(plt.subplot(M, 1, m + 1).get_xticklabels(), visible=False)\n",
    "    \n",
    "\n",
    "f, a = plt.subplots(4, sharex=True)\n",
    "plt.xlim([sig_start, sig_end])\n",
    "a[3].set_xlabel(\"Time [s]\")\n",
    "a[3].set_ylabel(\"Pr. [Pa]\")\n",
    "a[2].set_ylabel(\"Back Az. [deg.]\")\n",
    "a[1].set_ylabel(\"Tr. Vel. [m/s]\")\n",
    "if method == \"music\":\n",
    "    a[0].set_ylabel(\"Beam Power\")\n",
    "else:\n",
    "    a[0].set_ylabel(\"log10(F-value)\")\n",
    "\n",
    "a[3].plot(t, x[1,:], '-k')\n",
    "plt.suptitle(\"Detection Processing Results\")\n",
    "\n",
    "position = []     \n",
    "for det in range(len(dets)):\n",
    "    dt = dets[det][0]-times[0] \n",
    "    start = dt.item().total_seconds() \n",
    "    ts = sig_start + start + dets[det][1]\n",
    "    te = sig_start + start + dets[det][2]\n",
    "    a[3].axvspan(xmin = ts , xmax = te, alpha = 0.25, color = 'red')\n",
    "\n",
    "    duration = te-ts\n",
    "    duration = duration/window_step\n",
    "\n",
    "    for bb in range(0,int(duration),1):\n",
    "        temp = dets[det][0]+np.timedelta64(int(dets[det][1]),'s')+np.timedelta64(int(window_step*bb),'s')\n",
    "        det_time=find_nearest(times, temp)\n",
    "        det_times = np.where(times==det_time)\n",
    "        pos = det_times[0][0]\n",
    "        position.append(pos)\n",
    "for aa in range(len(times)):\n",
    "    dt = times[aa]-times[0]\n",
    "    start = dt.item().total_seconds() \n",
    "    start = start + sig_start\n",
    "    a[2].plot([start], [beam_results[aa][0]], 'ok', markersize=3.3)\n",
    "    a[1].plot([start], [beam_results[aa][1]], 'ok', markersize=3.3)\n",
    "    a[0].plot([start], [beam_results[aa][2]], 'ok', markersize=3.3)\n",
    "for aa in position:\n",
    "    dt = times[aa]-times[0]\n",
    "    start = dt.item().total_seconds() \n",
    "    start = start + sig_start\n",
    "    a[2].plot([start], [beam_results[aa][0]], 'or', markersize=3.3)\n",
    "    a[1].plot([start], [beam_results[aa][1]], 'or', markersize=3.3)\n",
    "    a[0].plot([start], [beam_results[aa][2]], 'or', markersize=3.3)\n",
    "\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "##      Plot Detection Results in Slowness Space      ##\n",
    "########################################################\n",
    "\n",
    "for det in range(len(dets)):\n",
    "    dt = dets[det][0]-times[0] \n",
    "    start = dt.item().total_seconds() \n",
    "    ts = sig_start + start + dets[det][1]\n",
    "    te = sig_start + start + dets[det][2]\n",
    "    X, S, f = beamforming_new.fft_array_data(x, t, window=[ts, te])\n",
    "    beam_power = beamforming_new.run(X, S, f, geom, delays, [freq_min, freq_max], method=method, signal_cnt=1, pool=p, ns_covar_inv=ns_covar_inv, normalize_beam=True)\n",
    "\n",
    "    avg_beam_power = np.average(beam_power, axis=0)\n",
    "        #avg_beam_power = beamforming_new.multi_freq_beam(beam_power)\n",
    "    print('Detection #' + str(det+1))\n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    plt.xlim([min(slowness[:, 0]), max(slowness[:, 0])])\n",
    "    plt.ylim([min(slowness[:, 1]), max(slowness[:, 1])])\n",
    "    if method == \"bartlett_covar\" or method == \"bartlett\" or method == \"gls\":\n",
    "        plt.scatter(slowness[:, 0], slowness[:, 1], c=avg_beam_power, cmap=palette, marker=\"o\", s=[12.5] * len(slowness), edgecolor='none', vmin=0.0, vmax=1.0)\n",
    "    else:\n",
    "        plt.scatter(slowness[:, 0], slowness[:, 1], c=avg_beam_power, cmap=palette, marker=\"o\", s=[12.5] * len(slowness), edgecolor='none', vmin=0.0, vmax=np.max(avg_beam_power))\n",
    "    plt.pause(1.0)\n",
    "\n",
    "    # Compute back azimuth projection of distribution\n",
    "    az_proj, tv_proj = beamforming_new.project_beam(beam_power, back_az_vals, trc_vel_vals, method=\"mean\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.suptitle(\"Average Beam Power\")\n",
    "\n",
    "    plt.clf()\n",
    "    plt.xlim([min(back_az_vals), max(back_az_vals)])\n",
    "    plt.xlabel('Backazimuth')\n",
    "    plt.ylabel('Avg. Beam Power')\n",
    "    if method == \"bartlett_covar\" or method == \"bartlett\" or method == \"gls\":\n",
    "        plt.ylim([0.0, 1.0])\n",
    "    else:\n",
    "        plt.ylim([0.0, np.max(avg_beam_power)])\n",
    "    plt.plot(back_az_vals, az_proj, '-k', linewidth=2.5)\n",
    "    plt.pause(0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association\n",
    "\n",
    "Associate a number of detections contained in a .dat file (/data/detection_set1.dat or /data/detection_set2.dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocess import Pool\n",
    "\n",
    "from infrapy.association import hjl\n",
    "from infrapy.propagation import likelihoods as lklhds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### Define parameters ###\n",
    "#########################\n",
    "\n",
    "# Read in detections from file\n",
    "det_list = lklhds.json_to_detection_list('../examples/data/detection_set1.json')\n",
    "\n",
    "# define joint-likelihood calculation parameters\n",
    "width = 10.0\n",
    "rng_max = 3000.0\n",
    "\n",
    "# define clustering parameters\n",
    "dist_max = 10.0\n",
    "clustering_threshold = 5.0\n",
    "trimming_thresh = 3.0\n",
    "\n",
    "pl = Pool(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "#### Run analysis ####\n",
    "######################\n",
    "labels, dists = hjl.run(det_list, clustering_threshold, dist_max=dist_max, bm_width=width, rng_max=rng_max, trimming_thresh=trimming_thresh, pool=pl,show_result=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#### Summarize Clusters ####\n",
    "############################\n",
    "clusters, qualities = hjl.summarize_clusters(labels, dists)\n",
    "for n in range(len(clusters)):\n",
    "    print(\"Cluster:\", clusters[n], '\\t', \"Cluster Quality:\", 10.0**(-qualities[n]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localization\n",
    "\n",
    "Test the Bayesian Infrasonic Source Localization (BISL) methodology using a set of provided detections (/data/detection_set1.dat or /data/detection_set2.dat).  Location will be run twice, once assuming uniform atmospheric propagation and a second time applying provided atmospheric propagation priors for the Western US (see Blom et al., 2015 for further explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from infrapy.location import bisl\n",
    "from infrapy.propagation import likelihoods as lklhds\n",
    "from infrapy.propagation import infrasound as infsnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################### #\n",
    "#       Define Inputs       #\n",
    "# ######################### #\n",
    "\n",
    "# Define ground_truth if known (41.131, -112.896 for UTTR; Test includes show in June 2004)\n",
    "grnd_trth = [41.131, -112.896, np.datetime64('2004-06-02T17:23:04.0')]\n",
    "\n",
    "# Define localization parameters\n",
    "bm_width = 12.5\n",
    "rad_min, rad_max = 50.0, 500.0\n",
    "rng_max = np.pi / 2.0 * 6370.0\n",
    "resolution = int(np.sqrt(1e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################# #\n",
    "#       Define Detection List       #\n",
    "# ################################# #\n",
    "\n",
    "'''\n",
    "# Define the list of detections (output from association)\n",
    "# detection format: (lat, lon, arrival time, back az, F stat, elements)\n",
    "# arrival time format: datetime.datetime(year, month, day, hour, minute, second)\n",
    "det1 = lklhds.InfrasoundDetection(42.7668, -109.5939, np.datetime64('2004-06-02T17:42:14.0'), -125.6, 75.0, 4)\n",
    "det2 = lklhds.InfrasoundDetection(38.4296, -118.3036, np.datetime64('2004-06-02T17:50:38.0'),   56.6, 75.0, 4)\n",
    "det3 = lklhds.InfrasoundDetection(48.2641, -117.1257, np.datetime64('2004-06-02T18:09:14.0'),  157.5, 75.0, 4)\n",
    "det_list = [det1, det2, det3]\n",
    "'''\n",
    "\n",
    "# Load detection list from flat file\n",
    "#det_list = lklhds.file2dets(\"data/detection_set2.dat\")\n",
    "\n",
    "# Load detection list from json file\n",
    "det_list = lklhds.json_to_detection_list('../examples/data/detection_set2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################## #\n",
    "#          Run BISL          #\n",
    "#       in Verbose Mode      #\n",
    "# ########################## #\n",
    "\n",
    "# Run analysis without priors\n",
    "result,pdf = bisl.run(det_list, \n",
    "                    bm_width=bm_width,\n",
    "                    rad_min=rad_min, \n",
    "                    rad_max=rad_max, \n",
    "                    rng_max=rng_max, \n",
    "                    resol=resolution,angle=[-180,180])\n",
    "\n",
    "summary = bisl.summarize(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################## #\n",
    "#     Display Results       #\n",
    "# ########################## #\n",
    "\n",
    "print('-' * 75)\n",
    "print('BISL Summary\\n')\n",
    "print(summary)\n",
    "print('\\n' + '-'*75 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################## #\n",
    "#          Define Priors,    #\n",
    "#          Load from File    #\n",
    "#           and Display      #\n",
    "# ########################## #\n",
    "\n",
    "model = infsnd.PathGeometryModel()\n",
    "model.load(\"../infrapy/propagation/priors/UTTR_models/UTTR_06_1800UTC.pgm\")\n",
    "#model.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################## #\n",
    "#          Run BISL          #\n",
    "#       in Verbose Mode      #\n",
    "# .       With Priors .      #\n",
    "# ########################## #\n",
    "\n",
    "result,pdf = bisl.run(det_list, \n",
    "                    bm_width=bm_width,\n",
    "                    rad_min=rad_min, \n",
    "                    rad_max=rad_max, \n",
    "                    rng_max=rng_max, \n",
    "                    resol=resolution,\n",
    "                    path_geo_model=model,angle=[-180,180])\n",
    "\n",
    "summary = bisl.summarize(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################## #\n",
    "#     Display Results       #\n",
    "# ########################## #\n",
    "\n",
    "print('-' * 75)\n",
    "print('BISL Summary\\n')\n",
    "print(summary)\n",
    "print('\\n' + '-'*75 + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yield Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.core import read\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from infrapy.utils import data_io\n",
    "from infrapy.propagation import infrasound\n",
    "\n",
    "from infrapy.characterization import spye\n",
    "if __name__ == '__main__':\n",
    "    # ######################### #\n",
    "    #     Define Parameters     #\n",
    "    # ######################### #\n",
    "    det_file = \"data/HRR-5.dets.json\"\n",
    "    wvfrm_path = \"../infrapy-data/hrr-5/*/*.sac\"\n",
    "    tloss_path = \"../infrapy/propagation/priors/tloss/2007_08-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_opt = \"post\"\n",
    "win_buffer = 0.2\n",
    "\n",
    "src_loc = np.array([33.5377, -106.333961])\n",
    "freq_band = np.array([0.25, 2.0])\n",
    "yld_rng = np.array([1.0e3, 1000.0e3])\n",
    "ref_rng = 1.0\n",
    "\n",
    "grnd_truth=None\n",
    "resol = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the detections and spectra\n",
    "\n",
    "det_list = data_io.json_to_detection_list(det_file)\n",
    "st_list = [Stream([tr for tr in read(wvfrm_path) if det.station in tr.stats.station]) for det in det_list]\n",
    "smn_specs = spye.extract_spectra(det_list, st_list, win_buffer=win_buffer, ns_opt=ns_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TLoss Models\n",
    "\n",
    "tloss_f_min, tloss_f_max, tloss_f_cnt = 0.025, 2.5, 25\n",
    "models = [0] * 2\n",
    "    models[0] = list(np.logspace(np.log10(tloss_f_min), np.log10(tloss_f_max), tloss_f_cnt))\n",
    "    models[1] = [0] * tloss_f_cnt\n",
    "    for n in range(tloss_f_cnt):\n",
    "        models[1][n] = infrasound.TLossModel()\n",
    "        models[1][n].load(tloss_path + \"%.3f\" % models[0][n] + \"Hz.pri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Yield Estimation Methods\n",
    "\n",
    "yld_results = spye.run(det_list, smn_specs, src_loc, freq_band, models, yld_rng=yld_rng, ref_src_rng=ref_rng, resol=resol)\n",
    "\n",
    "print('\\nResults:')\n",
    "print('\\t' + \"Maximum a Posteriori Yield:\", yld_results['yld_vals'][np.argmax(yld_results['yld_pdf'])])    print('\\t' + \"68% Confidence Bounds:\", yld_results['conf_bnds'][0])\n",
    "print('\\t' + \"95% Confidence Bounds:\", yld_results['conf_bnds'][1])\n",
    "\n",
    "plt.semilogx(yld_results['yld_vals'], yld_results['yld_pdf'])\n",
    "plt.fill_between(yld_results['yld_vals'], yld_results['yld_pdf'], where=np.logical_and(yld_results['conf_bnds'][0][0] <= yld_results['yld_vals'], yld_results['yld_vals'] <= yld_results['conf_bnds'][0][1]), color='g', alpha=0.25)\n",
    "plt.fill_between(yld_results['yld_vals'], yld_results['yld_pdf'], where=np.logical_and(yld_results['conf_bnds'][1][0] <= yld_results['yld_vals'], yld_results['yld_vals'] <= yld_results['conf_bnds'][1][1]), color='g', alpha=0.25)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Constants\n",
    "speed_of_sound = 343  # meters per second\n",
    "\n",
    "# Latitude and longitude of the mountain (source) and sensor (recording location)\n",
    "source_latitude = 40.7128  # Replace with the source latitude in degrees\n",
    "source_longitude = -74.0060  # Replace with the source longitude in degrees\n",
    "sensor_latitude = 34.0522  # Replace with the sensor latitude in degrees\n",
    "sensor_longitude = -118.2437  # Replace with the sensor longitude in degrees\n",
    "\n",
    "# Example infrasound signal timestamps\n",
    "timestamps = [0.0, 0.1, 0.2, 0.3, 0.4]  # Adjust with your actual timestamps\n",
    "\n",
    "# Calculate distance between source and sensor using haversine formula\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    r = 6371  # Earth's radius in kilometers\n",
    "    phi1 = math.radians(lat1)\n",
    "    phi2 = math.radians(lat2)\n",
    "    delta_phi = math.radians(lat2 - lat1)\n",
    "    delta_lambda = math.radians(lon2 - lon1)\n",
    "    a = math.sin(delta_phi / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = r * c * 1000  # Convert to meters\n",
    "    return distance\n",
    "\n",
    "distance_to_source = haversine(source_latitude, source_longitude, sensor_latitude, sensor_longitude)\n",
    "\n",
    "# Calculate time correction based on distance\n",
    "time_correction = distance_to_source / speed_of_sound\n",
    "\n",
    "# Apply time correction to timestamps\n",
    "corrected_timestamps = [timestamp + time_correction for timestamp in timestamps]\n",
    "\n",
    "# Print the original and corrected timestamps\n",
    "print(\"Original timestamps:\", timestamps)\n",
    "print(\"Corrected timestamps:\", corrected_timestamps)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95a8f6eb5a7fed2d9e90fd62b223dd819a4f5d56b58f6f02f1101b689472bced"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 64-bit ('infrapy_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
