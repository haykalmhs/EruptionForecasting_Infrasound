{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beamforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from obspy.core import read\n",
    "\n",
    "from infrapy.detection import beamforming_new\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ######################### #\n",
    "    #     Define Parameters     #\n",
    "    # ######################### #\n",
    "    sac_glob = \"data/YJ.BRP*.SAC\"\n",
    "    freq_min, freq_max = 0.5, 2.5\n",
    "    fk_win_len, window_step = 10.0, 2.5\n",
    "    sig_start, sig_end = 600, 800\n",
    "    back_az_vals = np.arange(-180.0, 180.0, 2.0)\n",
    "    trc_vel_vals = np.arange(300.0, 600.0, 2.5)\n",
    "\n",
    "    # ######################### #\n",
    "    #          Run Methods      #\n",
    "    # ######################### #\n",
    "    \n",
    "    # Read data and convert to array format\n",
    "    x, t, t0, geom = beamforming_new.stream_to_array_data(read(sac_glob))\n",
    "    M, N = x.shape\n",
    "\n",
    "    # Define slowness and delays\n",
    "    slowness = beamforming_new.build_slowness(back_az_vals, trc_vel_vals)\n",
    "    delays = beamforming_new.compute_delays(geom, slowness)\n",
    "    \n",
    "    # Run beamforming in each window and find best beam info\n",
    "    times, beam_results = [],[]\n",
    "    for window_start in np.arange(sig_start, sig_end, window_step):\n",
    "    if window_start + fk_win_len > sig_end:\n",
    "    break\n",
    "\n",
    "    X, S, f = beamforming_new.fft_array_data(x, t, window=[window_start, window_start + fk_win_len])\n",
    "    beam_power = beamforming_new.run(X, S, f, geom, delays, [freq_min, freq_max])\n",
    "    peaks = beamforming_new.find_peaks(beam_power, back_az_vals, trc_vel_vals)\n",
    "    times = times + [[t0 + np.timedelta64(int(window_start), 's')]]\n",
    "    beam_results = beam_results + [[peaks[0][0], peaks[0][1], peaks[0][2] / (1.0 - peaks[0][2]) * (x.shape[0] - 1)]]\n",
    "    times = np.array(times)[:, 0]\n",
    "    beam_results = np.array(beam_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameters \n",
    "\n",
    "# Detection params\n",
    "# times_file, beam_results_file = None, None\n",
    "times_file, beam_results_file = \"data/times.npy\", \"data/beam_results.npy\"\n",
    "\n",
    "det_win_len = 60 * 5\n",
    "det_thresh = 0.99\n",
    "min_seq = 5\n",
    "TB_prod = 40 * 10\n",
    "back_az_lim = 10\n",
    "channel_cnt = 4\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #Load data and prepare analysis \n",
    "\n",
    "    if times_file and beam_results_file:\n",
    "        times = np.load(times_file)\n",
    "        beam_results = np.load(beam_results_file)\n",
    "    else:\n",
    "        print('No beamforming input provided')\n",
    "\n",
    "    # Run detection analysis \n",
    "    # detect_signals(times, beam_results, win_len, TB_prod, channel_cnt, det_p_val=0.99, min_seq=5, back_az_lim=15, fixed_thresh=None, return_thresh=False)\n",
    "\n",
    "    dets = beamforming_new.detect_signals(times, beam_results, det_win_len, TB_prod, channel_cnt, min_seq=min_seq, back_az_lim=back_az_lim)\n",
    "\n",
    "    print('\\n' + \"Detection Summary:\")\n",
    "    for det in dets:\n",
    "        print(\"Detection time:\", det[0], '\\t', \"Rel. detection onset:\", det[1], '\\t',\"Rel. detection end:\", det[2], '\\t',end=' ')\n",
    "        print(\"Back azimuth:\", np.round(det[3], 2), '\\t', \"Trace velocity:\", np.round(det[4], 2), '\\t', \"F-stat:\", np.round(det[5], 2), '\\t', \"Array dim:\", channel_cnt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infrapy.association import hjl\n",
    "from infrapy.utils import data_io\n",
    "if __name__ == '__main__':\n",
    "    det_list = data_io.json_to_detection_list('data/example1.dets.json')\n",
    "    clustering_threshold = 5.0\n",
    "    \n",
    "    labels, dists = hjl.run(det_list, clustering_threshold)\n",
    "    \n",
    "    clusters, qualities = hjl.summarize_clusters(labels, dists)\n",
    "for n in range(len(clusters)):\n",
    "    print(\"Cluster:\", clusters[n], '\\t', \"Cluster Quality:\", 10.0**(qualities[n]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infrapy.location import bisl\n",
    "from infrapy.utils import data_io\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    det_list = data_io.json_to_detection_list('data/example2.dets.json')\n",
    "    \n",
    "    result,pdf = bisl.run(det_list)\n",
    "    print(bisl.summarize(result))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yield Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.core import read\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from infrapy.utils import data_io\n",
    "from infrapy.propagation import infrasound\n",
    "\n",
    "from infrapy.characterization import spye\n",
    "if __name__ == '__main__':\n",
    "    # ######################### #\n",
    "    #     Define Parameters     #\n",
    "    # ######################### #\n",
    "    det_file = \"data/HRR-5.dets.json\"\n",
    "    wvfrm_path = \"../infrapy-data/hrr-5/*/*.sac\"\n",
    "    tloss_path = \"../infrapy/propagation/priors/tloss/2007_08-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_opt = \"post\"\n",
    "win_buffer = 0.2\n",
    "\n",
    "src_loc = np.array([33.5377, -106.333961])\n",
    "freq_band = np.array([0.25, 2.0])\n",
    "yld_rng = np.array([1.0e3, 1000.0e3])\n",
    "ref_rng = 1.0\n",
    "\n",
    "grnd_truth=None\n",
    "resol = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the detections and spectra\n",
    "\n",
    "det_list = data_io.json_to_detection_list(det_file)\n",
    "st_list = [Stream([tr for tr in read(wvfrm_path) if det.station in tr.stats.station]) for det in det_list]\n",
    "smn_specs = spye.extract_spectra(det_list, st_list, win_buffer=win_buffer, ns_opt=ns_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TLoss Models\n",
    "\n",
    "tloss_f_min, tloss_f_max, tloss_f_cnt = 0.025, 2.5, 25\n",
    "models = [0] * 2\n",
    "    models[0] = list(np.logspace(np.log10(tloss_f_min), np.log10(tloss_f_max), tloss_f_cnt))\n",
    "    models[1] = [0] * tloss_f_cnt\n",
    "    for n in range(tloss_f_cnt):\n",
    "        models[1][n] = infrasound.TLossModel()\n",
    "        models[1][n].load(tloss_path + \"%.3f\" % models[0][n] + \"Hz.pri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Yield Estimation Methods\n",
    "\n",
    "yld_results = spye.run(det_list, smn_specs, src_loc, freq_band, models, yld_rng=yld_rng, ref_src_rng=ref_rng, resol=resol)\n",
    "\n",
    "print('\\nResults:')\n",
    "print('\\t' + \"Maximum a Posteriori Yield:\", yld_results['yld_vals'][np.argmax(yld_results['yld_pdf'])])    print('\\t' + \"68% Confidence Bounds:\", yld_results['conf_bnds'][0])\n",
    "print('\\t' + \"95% Confidence Bounds:\", yld_results['conf_bnds'][1])\n",
    "\n",
    "plt.semilogx(yld_results['yld_vals'], yld_results['yld_pdf'])\n",
    "plt.fill_between(yld_results['yld_vals'], yld_results['yld_pdf'], where=np.logical_and(yld_results['conf_bnds'][0][0] <= yld_results['yld_vals'], yld_results['yld_vals'] <= yld_results['conf_bnds'][0][1]), color='g', alpha=0.25)\n",
    "plt.fill_between(yld_results['yld_vals'], yld_results['yld_pdf'], where=np.logical_and(yld_results['conf_bnds'][1][0] <= yld_results['yld_vals'], yld_results['yld_vals'] <= yld_results['conf_bnds'][1][1]), color='g', alpha=0.25)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95a8f6eb5a7fed2d9e90fd62b223dd819a4f5d56b58f6f02f1101b689472bced"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 64-bit ('infrapy_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
