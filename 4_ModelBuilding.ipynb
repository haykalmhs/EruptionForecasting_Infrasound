{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model():\n",
    "    inp = Input(shape=(1, train_sample.shape[1]))\n",
    "    x = BatchNormalization()(inp)\n",
    "    x = LSTM(128, return_sequences=True)(x)\n",
    "    x = Convolution1D(128, (2), activation='relu', padding=\"same\")(x)\n",
    "    x = Convolution1D(84, (2), activation='relu', padding=\"same\")(x)\n",
    "    x = Convolution1D(64, (2), activation='relu', padding=\"same\")(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    ttf = Dense(1, activation='relu', name='regressor')(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=ttf)\n",
    "    opt = optimizers.Nadam(lr=0.005)\n",
    "    model.compile(optimizer=opt, loss='mae', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def normalize(X_train, X_valid, X_test, normalize_opt, excluded_feat):\n",
    "    feats = [f for f in X_train.columns if f not in excluded_feat]\n",
    "    if normalize_opt is not None:\n",
    "        if normalize_opt == 'min_max':\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "        scaler = scaler.fit(X_train[feats])\n",
    "        X_train[feats] = scaler.transform(X_train[feats])\n",
    "        X_valid[feats] = scaler.transform(X_valid[feats])\n",
    "        X_test[feats] = scaler.transform(X_test[feats])\n",
    "    return X_train, X_valid, X_test\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=K_FOLD, shuffle=True, random_state=1337)\n",
    "kf = list(kf.split(np.arange(len(train_sample))))\n",
    "\n",
    "oof_final = np.zeros(len(train_sample))\n",
    "sub_final = np.zeros(len(submission))\n",
    "i = 0\n",
    "while i < NB_MODELS:\n",
    "    print('Running Model ', i+1)\n",
    "\n",
    "    oof = np.zeros(len(train_sample))\n",
    "    prediction = np.zeros(len(submission))\n",
    "\n",
    "    for _, (train_index, valid_index) in enumerate(kf):\n",
    "\n",
    "        train_x = train_sample.iloc[train_index]\n",
    "        train_y = targets.iloc[train_index]\n",
    "\n",
    "        valid_x = train_sample.iloc[valid_index]\n",
    "        valid_y = targets.iloc[valid_index]\n",
    "\n",
    "        # #apply min max scaler on training, validation data\n",
    "        train_x, valid_x, test_scaled = normalize(train_x.copy(),\n",
    "                                                  valid_x.copy(),\n",
    "                                                  test.copy(), 'min_max', [])\n",
    "\n",
    "        train_x = train_x.values.reshape(train_x.shape[0], 1, train_x.shape[1])\n",
    "        valid_x = valid_x.values.reshape(valid_x.shape[0], 1, valid_x.shape[1])\n",
    "        test_scaled = test_scaled.values.reshape(test_scaled.shape[0],\n",
    "                                                 1, test_scaled.shape[1])\n",
    "\n",
    "        model = get_model()\n",
    "        cb_checkpoint = ModelCheckpoint(\"model.hdf5\",\n",
    "                                        monitor='val_mae',\n",
    "                                        save_weights_only=True,\n",
    "                                        save_best_only=True)\n",
    "\n",
    "        model.fit(train_x, train_y,\n",
    "                  epochs=EPOCHS, callbacks=[cb_checkpoint],\n",
    "                  batch_size=BATCH_SIZE, verbose=0,\n",
    "                  validation_data=(valid_x, [valid_y]))\n",
    "\n",
    "        model.load_weights(\"model.hdf5\")\n",
    "        oof[valid_index] += model.predict(valid_x).ravel()\n",
    "        prediction += model.predict(test_scaled).ravel()/K_FOLD\n",
    "        K.clear_session()\n",
    "\n",
    "    # Obtain the MAE for this run.\n",
    "    model_score = mse(targets, oof, squared=False)/1e6\n",
    "\n",
    "    if model_score < 2.77:\n",
    "        print(f'MAE: {model_score:.2f} averaged')\n",
    "        oof_final += oof/NB_MODELS\n",
    "        sub_final += prediction/NB_MODELS\n",
    "        i += 1\n",
    "    else:\n",
    "        print(f'MAE: {model_score:.2f} not averaged')\n",
    "\n",
    "\n",
    "print(f\"\\nMAE for NN: {mse(targets, oof_final, squared=False):.0f}\")\n",
    "submission['time_to_eruption'] = sub_final\n",
    "submission.to_csv(PATH_DATA + 'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infrapy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
